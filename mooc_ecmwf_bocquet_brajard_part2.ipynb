{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53802f5-6ba5-45ee-8404-efd7065a4133",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "resources": {
      "http://localhost:8080/custom.css": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      }
     }
    },
    "id": "a53802f5-6ba5-45ee-8404-efd7065a4133",
    "outputId": "fc4a5a66-323b-4c21-e933-5de4fa605532"
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<link rel=\"stylesheet\" href=\"custom.css\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0gdhCwxKgz59",
   "metadata": {
    "id": "0gdhCwxKgz59"
   },
   "source": [
    "## <span style=\"color:blue\"> Before you start, if you run on colab </span>...\n",
    "On colab, each notebook runs on its own environment, so you first need to run the following cell in order to download all the repository and to run the notebook part1.\n",
    "\n",
    "**Advice:** If it is not done, don't forget to change the Runtime type into \"GPU\" so to speed up the computations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BI6pdXhCg0Ye",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BI6pdXhCg0Ye",
    "outputId": "a5c00097-1066-4a14-e67f-00a19508a71b"
   },
   "outputs": [],
   "source": [
    "# First run configuration for colab\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    import os\n",
    "    print('Colab detected')\n",
    "    if os.path.isdir('2022-mooc-ecmwf-bocquet-brajard'):\n",
    "      %cd 2022-mooc-ecmwf-bocquet-brajard/\n",
    "    if not os.path.isfile('mooc_ecmwf_bocquet_brajard_part1.ipynb'):\n",
    "      \n",
    "      # Clone the git repository\n",
    "      !git clone https://github.com/marcbocquet/2022-mooc-ecmwf-bocquet-brajard.git\n",
    "\n",
    "      # Make the repository as working directory\n",
    "      %cd 2022-mooc-ecmwf-bocquet-brajard/\n",
    "\n",
    "    if not os.path.isfile('Output/xt.npy'):\n",
    "\n",
    "      # Run the notebook part 1\n",
    "      %run mooc_ecmwf_bocquet_brajard_part1.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923d2d94",
   "metadata": {
    "id": "923d2d94"
   },
   "source": [
    "# <span style=\"color:maroon\"> Data assimilation, machine learning, and dynamical systems - Part II  </span>\n",
    "#### Marc Bocquet¹ [marc.bocquet@enpc.fr](mailto:marc.bocquet@enpc.fr) and Julien Brajard² [julien.brajard@nersc.no](mailto:julien.brajard@nersc.no)\n",
    "#### (1) CEREA, École des Ponts et EdF R&D, Île-de-France, France\n",
    "#### (2) Nansen Center (NERSC), Bergen, Norway\n",
    "\n",
    "During this session, we will discover some connections between data assimilation and deep learning when applied to dynamical systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225f4f08-bba5-4b5d-b0c2-10c8b4d9cda8",
   "metadata": {
    "id": "225f4f08-bba5-4b5d-b0c2-10c8b4d9cda8"
   },
   "source": [
    "# <span style=\"color:teal\"> Second step: Learn the model error through machine learning.</span>\n",
    "\n",
    "In this notebook, we will use the output of data assimilation to train a neural network into predicting the model error. The procedure is the following:\n",
    "1. The **analysis** $x^{\\rm a}_k$ is used as the best possible estimate from the truth at time step $t_k$.\n",
    "2. The physical model is used to produced a **forecast** $x^{\\rm f}_{k}$ using the analysis $x^{\\rm a}_{k-1}$ as initial conditions.\n",
    "3. For each time $t_k$, the difference between the forecast and the analysis is used to estimate the **model error** $\\mathrm{err}_k = x^{\\rm a}_k - x^{\\rm f}_k$. Note that this value is called **analysis increment** in the context of data assimilation.\n",
    "4. A **neural network** taking $x^{\\rm a}_{k-1}$ as an input is trained, supervised by the data $\\mathrm{err}_k$\n",
    "<p align = \"center\">\n",
    "<img src=\"https://github.com/marcbocquet/2022-mooc-ecmwf-bocquet-brajard/blob/colab/Figures/scheme-err.png?raw=1\" alt=\"Model error estimation\" width=\"800\"/>\n",
    "</p>\n",
    "\n",
    "## <span style=\"color:blue\"> I. Check the result of data assimilation </span>\n",
    "Before training the neural network, as it is recommended for *any* machine learning process, we have a look at the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a567a4f-5cfc-4dbc-b2e7-9827fc7efd99",
   "metadata": {
    "id": "2a567a4f-5cfc-4dbc-b2e7-9827fc7efd99"
   },
   "outputs": [],
   "source": [
    "# Import standard modules\n",
    "import pathlib\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from pickle import dump\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow as tf\n",
    "from utils import tqdm_callback\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "from Model.neuralnet import Periodic1DPadding\n",
    "\n",
    "# Folder for results\n",
    "folder = dict(output = pathlib.Path(\"./Output\"))\n",
    "\n",
    "# For plot customisation\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('darkgrid')\n",
    "plt.rc('axes', linewidth=1)\n",
    "plt.rc('axes', edgecolor='k')\n",
    "plt.rc('figure', dpi=100)\n",
    "palette = sns.color_palette('deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2d5483-6222-4fcb-9a75-b6351f8d5e5c",
   "metadata": {
    "id": "3c2d5483-6222-4fcb-9a75-b6351f8d5e5c"
   },
   "source": [
    "First, we load the result of the data assimilation, the so-called **anlaysis**. We also load the truth to plot some diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d15ac0c-0fdf-43c1-bd02-973518a375ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2d15ac0c-0fdf-43c1-bd02-973518a375ee",
    "outputId": "d77dce86-f7d0-4953-eb11-fa1ed548103d"
   },
   "outputs": [],
   "source": [
    "# Load the analysis:\n",
    "xa = np.load(folder['output'] / 'xa.npy')\n",
    "\n",
    "# Load the truth\n",
    "xt = np.load(folder['output'] / 'xt.npy')\n",
    "\n",
    "print(f'Shape (number of samples, number of features) of the truth: {xt.shape}')\n",
    "print(f'Shape (number of samples, number of features) of the analysis: {xa.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e4b421-f901-477c-90de-de9bb237d0b2",
   "metadata": {
    "id": "f7e4b421-f901-477c-90de-de9bb237d0b2"
   },
   "source": [
    "Here we define the physical model so as to compute the forecast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d7713e-d6a3-4e8e-a5ff-7c380034dd6b",
   "metadata": {
    "id": "84d7713e-d6a3-4e8e-a5ff-7c380034dd6b"
   },
   "outputs": [],
   "source": [
    "# Check that the parameters of L96 are the same as in the first notebook.\n",
    "from Model.lorenz96 import l96\n",
    "Nx = 40\n",
    "dt = 0.05\n",
    "F = 8\n",
    "phi = l96(Nx, dt, F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d65b102-7814-4186-bc86-f598c3818515",
   "metadata": {
    "id": "7d65b102-7814-4186-bc86-f598c3818515"
   },
   "source": [
    "In the standard configuration, the best estimate we have from the system is the analysis. \n",
    "\n",
    "Here, as we know the truth, we can choose to use the true value of the L96 variable instead of the analysis.  Then, the data are **perfect**: there is no error due to the observation error, the observation sampling, and the data assimilation process. It is an ideal case, but it cannot be achieved for most realistic systems.\n",
    "\n",
    "If you want to do the test with perfect data, you just have to uncomment the line ```learning = 'truth'```. It is expected to be much easier to learn the model error as there is not additional noise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03950505-f3d7-4e2c-b3a6-dcf3982528a9",
   "metadata": {
    "id": "03950505-f3d7-4e2c-b3a6-dcf3982528a9"
   },
   "outputs": [],
   "source": [
    "learning = 'analysis'\n",
    "#learning = 'truth'\n",
    "if learning == 'analysis':\n",
    "    x = xa\n",
    "else:\n",
    "     x = xt #learn on the true error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd3c94f-2112-4f09-99e7-d3984dfbaf6d",
   "metadata": {
    "id": "5fd3c94f-2112-4f09-99e7-d3984dfbaf6d"
   },
   "outputs": [],
   "source": [
    "# Compute the forecast of the physical model\n",
    "xf = x + phi(x)\n",
    "\n",
    "# Compute the model error\n",
    "err = x[1:] - xf[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98480fc0-2f68-4b17-9029-5cb4efcb6d54",
   "metadata": {
    "id": "98480fc0-2f68-4b17-9029-5cb4efcb6d54"
   },
   "source": [
    "Now, we will compute and plot a diagnostic of the data assimilation. This diagnostic use the truth to evaluate the results, let's highlight that in a \"real-world\" case, the truth is not known and such diagnostics cannot be computed the same way. In such cases the truth is not known, observations can also be used, which come with additional challenges out of the scope of this module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefa853f-d86c-4d36-a112-84d86e673a71",
   "metadata": {
    "id": "eefa853f-d86c-4d36-a112-84d86e673a71"
   },
   "outputs": [],
   "source": [
    "# One utility function to compute scatter plots\n",
    "def scatter_plot(x,y,ax=None):\n",
    "    x, y = x.ravel(), y.ravel()\n",
    "    ax = sns.regplot(x=x, y=y, ax=ax)\n",
    "    r2 = r2_score(x, y)\n",
    "    mse = mean_squared_error(x, y, squared=False)\n",
    "    ax.set_title(f'R2={r2:.2f}, RMSE={mse:.2e}')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf0def8-6a83-4ebb-84d7-458daf41e712",
   "metadata": {
    "id": "ebf0def8-6a83-4ebb-84d7-458daf41e712"
   },
   "source": [
    "The RMSE in time is defined as\n",
    "$$\n",
    "\\mathrm{RMSE}(k) = \\sqrt{\\frac{1}{N_x} \\sum_{n=1}^{N_x} \\left( x^{\\rm t}_n - x^{\\rm a}_n \\right)^2},\n",
    "$$\n",
    "where $k$ is the index for the time, $n$ is the space index, $x^{\\rm t}_n$ is the true value and $x^{\\rm a}_n$ is the analysis (the result of the data assimilation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794e9760-f6fc-49c8-ae91-8827687a9e37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "id": "794e9760-f6fc-49c8-ae91-8827687a9e37",
    "outputId": "b4a3f389-03cd-4cd1-e507-1a8bd0a2d980"
   },
   "outputs": [],
   "source": [
    "rmse_time = np.sqrt(np.mean(np.square(xt-xa),axis=1))\n",
    "plt.plot(dt*np.arange(rmse_time.shape[0]),rmse_time)\n",
    "plt.plot(dt*np.arange(rmse_time.shape[0]), rmse_time.mean()*np.ones(rmse_time.shape[0]), ':k' )\n",
    "plt.xlabel('Time');\n",
    "plt.ylabel('Analysis RMSE');\n",
    "plt.title(f'RMSE (mean) = {rmse_time.mean():.3e}');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179b7fb3-c16d-4087-928a-a36ff6e5689f",
   "metadata": {
    "id": "179b7fb3-c16d-4087-928a-a36ff6e5689f"
   },
   "source": [
    "The dotted line is the mean of the RMSE, we should retrieve the same value as in part one of this session (around 0.2). We observe that, despite a couple of peaks, the RMSE is stable in time, which is a necessary condition. Indeed, in the following, we assume that the analysis is stationary, which means that its statistical properties do not depend on the time (for example there is no trend in the error).\n",
    "\n",
    "To have a sense of the accuracy of the analysis compared with the truth, we can also represent the analysis in the form of a scatter plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc75043-6488-4b60-b028-59aa2ce4365c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "id": "7fc75043-6488-4b60-b028-59aa2ce4365c",
    "outputId": "9a86e6b4-2b8b-45ad-c978-cfb05a9c80a5"
   },
   "outputs": [],
   "source": [
    "ax = scatter_plot (xt[:,20], xa[:,20])\n",
    "ax.set_xlabel('Truth')\n",
    "ax.set_ylabel('Analysis');\n",
    "plt.savefig('Figures/scatter_analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210e5b2f-0d47-4493-8ac6-7d279620ee2a",
   "metadata": {
    "id": "210e5b2f-0d47-4493-8ac6-7d279620ee2a"
   },
   "source": [
    "It appears clearly that the analysis is close to the true value, so the assumption that \"The analysis is the best estimate we have of the truth\" is reasonable.\n",
    "Note that the RMSE can be a bit different as it is the total RMSE for the variable 20, chosen arbitrary and not the mean RMSE in time for all the variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9202b765-6f46-4ff6-b481-bff4e95b9ea5",
   "metadata": {
    "id": "9202b765-6f46-4ff6-b481-bff4e95b9ea5"
   },
   "source": [
    "## <span style=\"color:blue\"> II. Build the neural network.</span>\n",
    "It is now time to define the neural network. We are using the Keras API of TensorFlow https://www.tensorflow.org/api_docs/python/tf/keras, the approach is of course also applicable using any deep-learning framework such as Pytorch https://pytorch.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198f78f7-01b9-415c-83f8-81df8e72c42e",
   "metadata": {
    "id": "198f78f7-01b9-415c-83f8-81df8e72c42e"
   },
   "source": [
    "We initialize random generators so the notebooks are fully reproducible. Several aspects are based on random processes:\n",
    "- The initialization of the weights of the neural network\n",
    "- The batch-sized chunk presented to the neural during the training are randomly shuffled at each epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9d2802-7a16-4184-85ed-1e7df1b2eca2",
   "metadata": {
    "id": "7c9d2802-7a16-4184-85ed-1e7df1b2eca2"
   },
   "outputs": [],
   "source": [
    "import random, os\n",
    "seed = 1980\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a76687-a309-40ba-9d0d-b9aac9160504",
   "metadata": {
    "id": "18a76687-a309-40ba-9d0d-b9aac9160504"
   },
   "source": [
    "We define the function that builds the neural net model as the form of a convolutional neural network. The function takes several input arguments:\n",
    "- `archi`: specify the hidden layers of the neural network as a form of a list of triplets. Each element of the list represents a hidden layer. A triplet is in the form of  `(nunits, kernelsize, activation)` where:\n",
    "    - `nunits` is the number of units (neurons) on the layer\n",
    "    - `filtersize` is the kernel size of the convolution \n",
    "    - `activation` is the activation function\n",
    "- `Nx`: is the spatial size of the problem (in our case: $N_x=40$)\n",
    "- `reg`: is the L2 wieght regularization of the output layer (default=1e-5). Can be set to zeros if you don't want to use regularization\n",
    "- `batchlayer`: Possibility to add batchnormalization before hidden layer (default is None). It is represented as a set of indexes. For example, specify `{0,2}` to have batchnormalization before the first and third hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64045b57-030a-4e49-aa6d-012ae661b73a",
   "metadata": {
    "id": "64045b57-030a-4e49-aa6d-012ae661b73a"
   },
   "outputs": [],
   "source": [
    "def buildmodel(archi, Nx=40, reg=1e-5, batchlayer={}):\n",
    "\n",
    "    # Input Layer:\n",
    "    inputs = Input(shape=(Nx,1))\n",
    "    \n",
    "    # Pre-processing layer to account for the periodicity of the space:\n",
    "    border = int(np.sum(np.array([kern//2 for nfil,kern,activ in archi])))\n",
    "    x = Periodic1DPadding(padding_size=border)(inputs)\n",
    "    \n",
    "    # BatchNormalization layer\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Definition of the hidden layers\n",
    "    for i, (nfil, kern, activ) in enumerate(archi):\n",
    "        if i in batchlayer:\n",
    "            x = BatchNormalization()(x)\n",
    "        x = Conv1D(nfil, kern, activation=activ)(x)\n",
    "        \n",
    "    # Ouput layer (with optional regularization)\n",
    "    output= Conv1D(1,1,activation='linear', kernel_regularizer=regularizers.l2(reg))(x)\n",
    "    return Model(inputs,output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3ed55e-2ca4-4bc2-934d-6c81f2d24a3e",
   "metadata": {
    "id": "5c3ed55e-2ca4-4bc2-934d-6c81f2d24a3e"
   },
   "outputs": [],
   "source": [
    "#We propose here a default neural network setting but feel free to play with the neural net characteristics\n",
    "\n",
    "archi = [(40, 7, 'tanh'),\n",
    "         (20, 5, 'tanh'),\n",
    "         (20, 1, 'tanh')\n",
    "        ]\n",
    "model = buildmodel(archi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b32c90a-88d7-460a-b295-50613e1eba3c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 754
    },
    "id": "7b32c90a-88d7-460a-b295-50613e1eba3c",
    "outputId": "d0478049-0460-4a4e-d365-4b9a7060868a"
   },
   "outputs": [],
   "source": [
    "# We can plot the architecture of our model\n",
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bb83b7-c479-4bf5-877f-b7d1c70b2d7d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "68bb83b7-c479-4bf5-877f-b7d1c70b2d7d",
    "outputId": "5865631a-b165-4394-903c-3597abf184c5"
   },
   "outputs": [],
   "source": [
    "# We can also have a summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20a5c4b-1ea6-480d-9f71-02791fd07b3b",
   "metadata": {
    "id": "d20a5c4b-1ea6-480d-9f71-02791fd07b3b"
   },
   "source": [
    "## <span style=\"color:blue\"> III. Train the neural network.</span>\n",
    "In this section, the neural network defined previously is trained. The dataset is divided into two parts: the training set used to optimize the weights, and the validation set to follow the evolution of the metric and avoid overfitting.\n",
    "\n",
    "The training/validation is defined with two parameters:\n",
    "- `frac_train` (default: 0.8): Fraction of the data selected as training data, the rest is used for validation\n",
    "- `valend` (default: True): Flag to indicate if the validation is taken at the end of the analysis (if True) or at the beginning of the analysis (if False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781ff538-f95a-4e51-b2a5-a48e9ef24873",
   "metadata": {
    "id": "781ff538-f95a-4e51-b2a5-a48e9ef24873"
   },
   "outputs": [],
   "source": [
    "frac_train = .8\n",
    "valend = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d401b0-21ce-43f3-900b-b94e9ea92be5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d8d401b0-21ce-43f3-900b-b94e9ea92be5",
    "outputId": "bebe4c54-9105-46ad-b0e9-b99904a1abf4"
   },
   "outputs": [],
   "source": [
    "# Split in train/validation\n",
    "X = x[:-1]\n",
    "y = err\n",
    "\n",
    "itrain = int(frac_train*X.shape[0])\n",
    "if valend == True:\n",
    "    Xtrain, ytrain = X[:itrain], y[:itrain]\n",
    "    Xval, yval = X[itrain:], y[itrain:]\n",
    "else:\n",
    "    Xtrain, ytrain = X[-itrain:], y[-itrain:]\n",
    "    Xval, yval = X[:-itrain], y[:-itrain]\n",
    "print(f'Total number of samples: {X.shape[0]}')\n",
    "print(f'Number of training samples: {Xtrain.shape[0]}')\n",
    "print(f'Number of validation samples: {Xval.shape[0]}')\n",
    "print(f'Number of input features: {Xval.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d3954a-00f9-46de-8f04-7015ecd7e36c",
   "metadata": {
    "id": "86d3954a-00f9-46de-8f04-7015ecd7e36c"
   },
   "source": [
    "The data presented as an input or output are standardised to facilitate the training. Important: the scaling factors (mean and standard deviation) are computed on the training set only, and the same values will be applied for validation and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c958c329-fd2f-49f7-aaea-10061fc3bdbc",
   "metadata": {
    "id": "c958c329-fd2f-49f7-aaea-10061fc3bdbc"
   },
   "outputs": [],
   "source": [
    "scaler_x = StandardScaler().fit(Xtrain)\n",
    "scaler_y = StandardScaler().fit(ytrain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738695aa-fb23-420d-b08d-3b44bae0cf01",
   "metadata": {
    "id": "738695aa-fb23-420d-b08d-3b44bae0cf01"
   },
   "source": [
    "The model is compiled as required by the keras API. The loss function optimized is the mean square error and the chosen optimiser is `Adam` (see https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile for more details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2598dc-19ad-4782-92f8-de4ffb183a71",
   "metadata": {
    "id": "8b2598dc-19ad-4782-92f8-de4ffb183a71"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e1b8d6-721b-4c93-ba97-8aa748b8d37b",
   "metadata": {
    "id": "c8e1b8d6-721b-4c93-ba97-8aa748b8d37b"
   },
   "source": [
    "To fit the model to the data, we specify the number of epochs. The evolution of the metrics during the training is saved in the `history` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dec98b-e95d-4b93-9744-7115da6dae7b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "a9ea5126feb24559b66dcc22b49165eb",
      "0df96b3a637f468591ed4736008f6d7a",
      "b5bf14464e5a455fbeb3a111ba9c4fc0",
      "3cfb2e3aa3e24f0687aeff795719e99a",
      "9580fa715bf5432d95c6cbdf48b9eb6f",
      "d287926c9d0349b381854252c192b73d",
      "f489c206113e44dcafcca80c8aa9da49",
      "666aec8716de48bcb8846d462510d726",
      "7bc1ffa27e274267bee8fcfbddfbabf3",
      "3e0534dae3bb4f6895318a09d2ad2735",
      "954feed8acb44551ae1e218fe5c3b39d"
     ]
    },
    "id": "56dec98b-e95d-4b93-9744-7115da6dae7b",
    "outputId": "fc9d43f9-2b0b-4463-d0d5-02bb365e2e18"
   },
   "outputs": [],
   "source": [
    "num_epochs = 500\n",
    "\n",
    "# We define a callback to follow the evolution of the training\n",
    "callbacks = [ tqdm_callback(num_epochs, 'NN training') ]\n",
    "\n",
    "history = model.fit(scaler_x.transform(Xtrain), scaler_y.transform(ytrain), \n",
    "                    epochs=num_epochs, \n",
    "                    batch_size=256, \n",
    "                    validation_data = (scaler_x.transform(Xval), scaler_y.transform(yval)),\n",
    "                    verbose=0, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba0cf8e-7d88-44ee-b452-27343387a17a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "3ba0cf8e-7d88-44ee-b452-27343387a17a",
    "outputId": "a39294f8-bf56-47aa-eee4-2ac0d742ca66"
   },
   "outputs": [],
   "source": [
    "# Plot the learning curve\n",
    "plt.semilogy(history.history['loss'], color='gray', label='training loss')\n",
    "plt.semilogy(history.history['val_loss'], color='black', label='validation loss')\n",
    "plt.legend()\n",
    "plt.savefig('Figures/learning_curve')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b23dfe-23f2-4ed0-9767-f9f92b884a0f",
   "metadata": {
    "id": "61b23dfe-23f2-4ed0-9767-f9f92b884a0f"
   },
   "source": [
    "We expect both validation and training loss to decrease. If the validation stabilise or increase while the training loss continues to decrease, it means that the neural network overfits on the training set. In that case, the training can be stopped earlier by reducing the number of epochs (it is called \"Early stopping\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2817e9eb-9d9b-4dfa-80bc-def5f7de70c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2817e9eb-9d9b-4dfa-80bc-def5f7de70c2",
    "outputId": "f98d540b-79ad-409b-9d55-f3c9008e09af"
   },
   "outputs": [],
   "source": [
    "# Save the model and the standardisation coefficients\n",
    "if learning=='analysis':\n",
    "    name = 'damodel'\n",
    "else:\n",
    "    name = 'true_model'\n",
    "model.save(folder['output'] / f'{name}_nn')\n",
    "dump(scaler_x, open(folder['output'] / f'{name}_scalerx', 'wb'))\n",
    "dump(scaler_y, open(folder['output'] / f'{name}_scalery', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973230a5-686a-4baf-9a55-1966c3a8e517",
   "metadata": {
    "id": "973230a5-686a-4baf-9a55-1966c3a8e517"
   },
   "source": [
    "## <span style=\"color:blue\"> IV. Validate the model (offline).</span>\n",
    "In this section, we apply the neural network to the validation dataset and see how well the neural net has been trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a7cd0e-3d94-41e7-9c5c-4fa1c6c30454",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15a7cd0e-3d94-41e7-9c5c-4fa1c6c30454",
    "outputId": "e34a545a-85dc-48b8-d242-a85b589e8d66"
   },
   "outputs": [],
   "source": [
    "ypredict = scaler_y.inverse_transform(model.predict(scaler_x.transform(Xval)).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effce0c6-37d2-4ae4-b127-24eb04e9e826",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "id": "effce0c6-37d2-4ae4-b127-24eb04e9e826",
    "outputId": "48a39f75-d6b9-4e2a-be7c-c286fc23a217"
   },
   "outputs": [],
   "source": [
    "ax = scatter_plot (yval[:,20], ypredict[:,20])\n",
    "ax.set_xlabel('target error')\n",
    "ax.set_ylabel('predicted error');\n",
    "ax.axis('equal');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09266f98-55bc-4654-8016-3cfb3c983247",
   "metadata": {
    "id": "09266f98-55bc-4654-8016-3cfb3c983247"
   },
   "source": [
    "There is a significant correlation between the target error and the predicted error (around 0.18), which is what we hoped for.\n",
    "The neural network is supposed to learn the model error: if the analysis is used, the model error is estimated and therefore noisy because of the noise in the observation and the uncertainty of the analysis. So ideally, we don't aim at a correlation of 1, since it would mean that the neural network has fitted also the noise of the data. On the contrary, if the neural is trained using the *true* model error (`learning=truth`), you aim at the best possible correlation."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0df96b3a637f468591ed4736008f6d7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d287926c9d0349b381854252c192b73d",
      "placeholder": "​",
      "style": "IPY_MODEL_f489c206113e44dcafcca80c8aa9da49",
      "value": "NN training: 100%"
     }
    },
    "3cfb2e3aa3e24f0687aeff795719e99a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e0534dae3bb4f6895318a09d2ad2735",
      "placeholder": "​",
      "style": "IPY_MODEL_954feed8acb44551ae1e218fe5c3b39d",
      "value": " 500/500 [00:58&lt;00:00, 10.26it/s, mse=0.796, val_mse=0.815]"
     }
    },
    "3e0534dae3bb4f6895318a09d2ad2735": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "666aec8716de48bcb8846d462510d726": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7bc1ffa27e274267bee8fcfbddfbabf3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "954feed8acb44551ae1e218fe5c3b39d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9580fa715bf5432d95c6cbdf48b9eb6f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a9ea5126feb24559b66dcc22b49165eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0df96b3a637f468591ed4736008f6d7a",
       "IPY_MODEL_b5bf14464e5a455fbeb3a111ba9c4fc0",
       "IPY_MODEL_3cfb2e3aa3e24f0687aeff795719e99a"
      ],
      "layout": "IPY_MODEL_9580fa715bf5432d95c6cbdf48b9eb6f"
     }
    },
    "b5bf14464e5a455fbeb3a111ba9c4fc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_666aec8716de48bcb8846d462510d726",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7bc1ffa27e274267bee8fcfbddfbabf3",
      "value": 500
     }
    },
    "d287926c9d0349b381854252c192b73d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f489c206113e44dcafcca80c8aa9da49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
