{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc6d261f",
   "metadata": {},
   "source": [
    "# <span style=\"color:maroon\"> Data assimilation, machine learning and dynamical systems - Part III  </span>\n",
    "#### Marc Bocquet¹ [marc.bocquet@enpc.fr](mailto:marc.bocquet@enpc.fr) and Julien Brajard² [julien.brajard@nersc.no](mailto:julien.brajard@nersc.no)\n",
    "#### (1) CEREA, École des Ponts et EdF R&D, Île-de-France, France\n",
    "#### (2) Nansen Center (NERSC), Bergen, Norway\n",
    "\n",
    "During this session, we will discover some connections between data assimilation and deep learning when applied to dynamical systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d1bc00e-b1e9-496f-9efb-b3acb6d22cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 11:28:56.467461: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from utils import scatter_plot\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76797d0d-c566-471e-9659-8b3e57abbd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = dict(output = pathlib.Path(\"./Output\"))\n",
    "\n",
    "# For plot customisation\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('darkgrid')\n",
    "plt.rc('axes', linewidth=1)\n",
    "plt.rc('axes', edgecolor='k')\n",
    "plt.rc('figure', dpi=100)\n",
    "palette = sns.color_palette('deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4486d96-6946-4fc9-bcc6-62c423cad1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = np.load(dir['output'] / 'xt.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da293dca-336d-4d28-98e1-1af0ccaa0b8e",
   "metadata": {},
   "source": [
    "## Construct the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f544ca15-a87c-47ac-9cc3-8526e99795d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model.lorenz96_cubic import l96cb\n",
    "\n",
    "Nx = 40\n",
    "dt = 0.05\n",
    "F = 8.5\n",
    "diffusion = 0.025\n",
    "friction = 1.1\n",
    "tmodel = l96cb(Nx, dt, F, diffusion, friction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d29e2ff4-8377-4b18-83ab-c3fe317858d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fbc38ca40ab4bd794c8573c9c6eccc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test model integration:   0%|          | 0/9999 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Nt_test = 10000\n",
    "Nx = xt.shape[1]\n",
    "xtest = np.zeros((Nt_test, Nx))\n",
    "xtest[0] = xt[-1]\n",
    "for t in trange(1, Nt_test, desc='test model integration'):\n",
    "    xtest[t] = xtest[t-1] + tmodel(xtest[t-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19f307cc-7ffd-40cb-8348-3556e200d7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape to have an ensemble\n",
    "Nt_forecast = 200\n",
    "Xtest = xtest.reshape(-1, Nt_forecast, Nx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a86fba-5599-4d81-b1b6-48086f687fd8",
   "metadata": {},
   "source": [
    "## Construct the hybrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e161f889-14e4-4bca-83f3-551650a046f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "damodel\n"
     ]
    }
   ],
   "source": [
    "learning = 'analysis'\n",
    "if learning=='analysis':\n",
    "    name = 'damodel'\n",
    "else:\n",
    "    name = 'true_model'\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d988dc6c-9d6a-44bc-8c1f-bb33ccda926d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "from Model.lorenz96 import l96\n",
    "class l96hybrid(l96):\n",
    "    def __init__(self, saved_model, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.saved_model = saved_model\n",
    "        fnn = f'{self.saved_model}_nn'\n",
    "        scalerx =  f'{self.saved_model}_scalerx'\n",
    "        scalery =  f'{self.saved_model}_scalery'\n",
    "        self.scaler_x = pickle.load(open(scalerx, 'rb'))\n",
    "        self.scaler_y = pickle.load(open(scalery, 'rb'))\n",
    "        self.nn = load_model(fnn)\n",
    "    def __call__(self, q):\n",
    "        dq_phi = super().__call__(q)\n",
    "        #dq_nn =  self.scaler_y.inverse_transform(self.nn.predict(self.scaler_x.transform(q), verbose=0).squeeze())\n",
    "        dq_nn =  self.scaler_y.inverse_transform(self.nn(self.scaler_x.transform(q)).numpy().squeeze())\n",
    "        return dq_phi + dq_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0727933-ddf2-4c25-a171-6694189bbfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = dir['output'] / name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae5d307f-be41-46ae-95f8-32582fb4a094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 11:28:58.805223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 11:28:58.817233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 11:28:58.817383: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 11:28:58.817742: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-20 11:28:58.818504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 11:28:58.818626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 11:28:58.818727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 11:28:59.111230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 11:28:59.111365: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 11:28:59.111468: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 11:28:59.111544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 108 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:0c:00.0, compute capability: 8.6\n",
      "2022-12-20 11:28:59.120201: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 108.81M (114098176 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-12-20 11:28:59.120667: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 97.93M (102688512 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-12-20 11:28:59.121120: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 88.14M (92419840 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    }
   ],
   "source": [
    "Nx = 40\n",
    "dt = 0.05\n",
    "F = 8\n",
    "phi = l96(Nx, dt, F)\n",
    "hyb_model = l96hybrid(Nx=Nx, dt=dt, F=F, saved_model=saved_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd246c2-4442-48c7-8251-4f6b9947ddf5",
   "metadata": {},
   "source": [
    "## Run hybrid and physical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69e4d0f7-0d1b-49b4-956c-92d822cbe941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f7add0fb6f48418d9a08b7fd9d5936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "proxy model integration:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xphi = np.zeros_like(Xtest)\n",
    "xphi[:,0] = Xtest[:,0]\n",
    "for t in trange(1, Nt_forecast, desc='proxy model integration'):\n",
    "    xphi[:,t] = xphi[:,t-1] + phi(xphi[:,t-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe6ad2ad-3579-45bd-80d2-09869c5a84ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f65866a68e41b4ab2b3adcff6b1bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "proxy model integration:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 11:28:59.539128: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2022-12-20 11:28:59.539164: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at conv_ops.cc:1134 : UNIMPLEMENTED: DNN library is not found.\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Exception encountered when calling layer \"conv1d\" \"                 f\"(type Conv1D).\n\n{{function_node __wrapped__Conv2D_device_/job:localhost/replica:0/task:0/device:GPU:0}} DNN library is not found. [Op:Conv2D]\n\nCall arguments received by layer \"conv1d\" \"                 f\"(type Conv1D):\n  • inputs=tf.Tensor(shape=(50, 50, 1), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m xhyb[:,\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m Xtest[:,\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;241m1\u001b[39m, Nt_forecast, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproxy model integration\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     xhyb[:,t] \u001b[38;5;241m=\u001b[39m xhyb[:,t\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[43mhyb_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxhyb\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m, in \u001b[0;36ml96hybrid.__call__\u001b[0;34m(self, q)\u001b[0m\n\u001b[1;32m     15\u001b[0m dq_phi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(q)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#dq_nn =  self.scaler_y.inverse_transform(self.nn.predict(self.scaler_x.transform(q), verbose=0).squeeze())\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m dq_nn \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler_y\u001b[38;5;241m.\u001b[39minverse_transform(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39msqueeze())\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dq_phi \u001b[38;5;241m+\u001b[39m dq_nn\n",
      "File \u001b[0;32m~/mambaforge/envs/tfm-gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/mambaforge/envs/tfm-gpu/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7208\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7209\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Exception encountered when calling layer \"conv1d\" \"                 f\"(type Conv1D).\n\n{{function_node __wrapped__Conv2D_device_/job:localhost/replica:0/task:0/device:GPU:0}} DNN library is not found. [Op:Conv2D]\n\nCall arguments received by layer \"conv1d\" \"                 f\"(type Conv1D):\n  • inputs=tf.Tensor(shape=(50, 50, 1), dtype=float32)"
     ]
    }
   ],
   "source": [
    "xhyb = np.zeros_like(Xtest)\n",
    "xhyb[:,0] = Xtest[:,0]\n",
    "for t in trange(1, Nt_forecast, desc='proxy model integration'):\n",
    "    xhyb[:,t] = xhyb[:,t-1] + hyb_model(xhyb[:,t-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab20d62-5f29-4973-b1a8-7897c95a9852",
   "metadata": {},
   "source": [
    "## Plot scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb20d226-0157-4925-b89e-aa6771119cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 6))\n",
    "plt.grid(False)\n",
    "im = plt.imshow(Xtest[0].T, \n",
    "           aspect = 'auto',\n",
    "           origin = 'lower',\n",
    "           interpolation = 'spline36',\n",
    "           cmap = sns.diverging_palette(240, 60, as_cmap=True),\n",
    "           extent = [0, dt*Xtest[0].shape[0], 0, Nx],\n",
    "           vmin = -10,\n",
    "           vmax = 15)\n",
    "plt.colorbar(im)\n",
    "plt.xlabel('Time (MTU)')\n",
    "plt.ylabel('Lorenz 96 variables')\n",
    "plt.tick_params(direction='out', left=True, bottom=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1c69af-378e-4b21-bf3d-2cad0462eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 6))\n",
    "plt.grid(False)\n",
    "im = plt.imshow(xhyb[0].T, \n",
    "           aspect = 'auto',\n",
    "           origin = 'lower',\n",
    "           interpolation = 'spline36',\n",
    "           cmap = sns.diverging_palette(240, 60, as_cmap=True),\n",
    "           extent = [0, dt*xhyb[0].shape[0], 0, Nx],\n",
    "           vmin = -10,\n",
    "           vmax = 15)\n",
    "plt.colorbar(im)\n",
    "plt.xlabel('Time (MTU)')\n",
    "plt.ylabel('Lorenz 96 variables')\n",
    "plt.tick_params(direction='out', left=True, bottom=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f96a333-2e5d-4e98-a5b2-e72af5f7af58",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 6))\n",
    "plt.grid(False)\n",
    "im = plt.imshow(xphi[0].T, \n",
    "           aspect = 'auto',\n",
    "           origin = 'lower',\n",
    "           interpolation = 'spline36',\n",
    "           cmap = sns.diverging_palette(240, 60, as_cmap=True),\n",
    "           extent = [0, dt*xhyb[0].shape[0], 0, Nx],\n",
    "           vmin = -10,\n",
    "           vmax = 15)\n",
    "plt.colorbar(im)\n",
    "plt.xlabel('Time (MTU)')\n",
    "plt.ylabel('Lorenz 96 variables')\n",
    "plt.tick_params(direction='out', left=True, bottom=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4efbd7-12a7-431a-bb1f-99e75c2faa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_phi = np.sqrt(np.mean(np.square(Xtest-xphi),axis=(0,2))/2)\n",
    "rmse_hyb = np.sqrt(np.mean(np.square(Xtest-xhyb),axis=(0,2))/2)\n",
    "mod_var = np.std(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18bd988-dbe2-4231-9ead-29d65842674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 6))\n",
    "plt.plot(dt*np.arange(Nt_forecast), rmse_phi, label='physical model')\n",
    "plt.plot(dt*np.arange(Nt_forecast), rmse_hyb, label='hybrid model')\n",
    "plt.plot(dt*np.arange(Nt_forecast), mod_var*np.ones(Nt_forecast),':k', label='True model varaibility')\n",
    "plt.legend()\n",
    "plt.xlabel('Time (MTU)')\n",
    "plt.ylabel('RMSE')\n",
    "plt.savefig(f'Figures/rmse_{name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf257a3a-abbb-447a-bbc9-4636b310c0df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
